{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6c9f386f810e4a80954246e91facd716": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c5f3341d41e54edfb5f2bff410ae4327",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1b6be836b7654120843717bd36130198",
              "IPY_MODEL_2afde0174d1943b7b3216cd73bf4a550"
            ]
          }
        },
        "c5f3341d41e54edfb5f2bff410ae4327": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b6be836b7654120843717bd36130198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_28b4f527b0aa4860b11f0f5d14a0c2b3",
            "_dom_classes": [],
            "description": "Dl Completed...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_85601751ea3b4bd58e9f72cc73be9502"
          }
        },
        "2afde0174d1943b7b3216cd73bf4a550": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d23292db2f1e42e1ac63ccd4905d17ab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/4 [00:01&lt;00:00,  2.19 file/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_243ff4f87c3b4c89ad9cca4487239cb9"
          }
        },
        "28b4f527b0aa4860b11f0f5d14a0c2b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "85601751ea3b4bd58e9f72cc73be9502": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d23292db2f1e42e1ac63ccd4905d17ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "243ff4f87c3b4c89ad9cca4487239cb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C40qVm-cUxbx"
      },
      "source": [
        "# No Distreibuted Strategy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpEiaLQtPJfj",
        "outputId": "96f94509-05e8-4100-dd5c-b327c9458e5d"
      },
      "source": [
        "import tensorflow_datasets as tfds\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "# Load the dataset we'll use for this lab\r\n",
        "datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True, data_dir='data')\r\n",
        "mnist_train, mnist_test = datasets['train'], datasets['test']\r\n",
        "\r\n",
        "# Get the number of examples in the train and test sets\r\n",
        "num_train_examples = info.splits['train'].num_examples\r\n",
        "num_test_examples = info.splits['test'].num_examples\r\n",
        "\r\n",
        "BUFFER_SIZE = 10000\r\n",
        "\r\n",
        "BATCH_SIZE_PER_REPLICA = 64\r\n",
        "# Use for Mirrored Strategy\r\n",
        "# BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\r\n",
        "# Use for No Strategy\r\n",
        "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * 1\r\n",
        "\r\n",
        "# Function for normalizing the image\r\n",
        "def scale(image, label):\r\n",
        "    image = tf.cast(image, tf.float32)\r\n",
        "    image /= 255\r\n",
        "\r\n",
        "    return image, label\r\n",
        "\r\n",
        "# Set up the train and eval data set\r\n",
        "train_dataset = mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\r\n",
        "eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)\r\n",
        "\r\n",
        "model = tf.keras.Sequential([\r\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\r\n",
        "    tf.keras.layers.MaxPooling2D(),\r\n",
        "    tf.keras.layers.Flatten(),\r\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\r\n",
        "    tf.keras.layers.Dense(10)\r\n",
        "    ])\r\n",
        "\r\n",
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
        "                optimizer=tf.keras.optimizers.Adam(),\r\n",
        "                metrics=['accuracy'])\r\n",
        "\r\n",
        "model.fit(train_dataset, epochs=5)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "938/938 [==============================] - 7s 6ms/step - loss: 0.4091 - accuracy: 0.8833\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0697 - accuracy: 0.9794\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0485 - accuracy: 0.9857\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0341 - accuracy: 0.9899\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0271 - accuracy: 0.9914\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f42c9286a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YI0HswXUjBY"
      },
      "source": [
        "# Mirrored Strategy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508,
          "referenced_widgets": [
            "6c9f386f810e4a80954246e91facd716",
            "c5f3341d41e54edfb5f2bff410ae4327",
            "1b6be836b7654120843717bd36130198",
            "2afde0174d1943b7b3216cd73bf4a550",
            "28b4f527b0aa4860b11f0f5d14a0c2b3",
            "85601751ea3b4bd58e9f72cc73be9502",
            "d23292db2f1e42e1ac63ccd4905d17ab",
            "243ff4f87c3b4c89ad9cca4487239cb9"
          ]
        },
        "id": "2izgECmIPGn6",
        "outputId": "49c9703f-1f2b-4d8b-f4de-0d601ff88ddc"
      },
      "source": [
        "%reset -f\r\n",
        "import tensorflow_datasets as tfds\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "# Load the dataset we'll use for this lab\r\n",
        "datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True, data_dir='data')\r\n",
        "mnist_train, mnist_test = datasets['train'], datasets['test']\r\n",
        "\r\n",
        "# Get the number of examples in the train and test sets\r\n",
        "num_train_examples = info.splits['train'].num_examples\r\n",
        "num_test_examples = info.splits['test'].num_examples\r\n",
        "\r\n",
        "# Function for normalizing the image\r\n",
        "def scale(image, label):\r\n",
        "    image = tf.cast(image, tf.float32)\r\n",
        "    image /= 255\r\n",
        "\r\n",
        "    return image, label\r\n",
        "\r\n",
        "# Define the strategy to use and print the number of devices found\r\n",
        "strategy = tf.distribute.MirroredStrategy()\r\n",
        "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\r\n",
        "\r\n",
        "BUFFER_SIZE = 10000\r\n",
        "\r\n",
        "BATCH_SIZE_PER_REPLICA = 64\r\n",
        "# Use for Mirrored Strategy\r\n",
        "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\r\n",
        "# Use for No Strategy\r\n",
        "# BATCH_SIZE = BATCH_SIZE_PER_REPLICA * 1\r\n",
        "\r\n",
        "# Set up the train and eval data set\r\n",
        "train_dataset = mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\r\n",
        "eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)\r\n",
        "\r\n",
        "\r\n",
        "with strategy.scope():\r\n",
        "    model = tf.keras.Sequential([\r\n",
        "        tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\r\n",
        "        tf.keras.layers.MaxPooling2D(),\r\n",
        "        tf.keras.layers.Flatten(),\r\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\r\n",
        "        tf.keras.layers.Dense(10)\r\n",
        "        ])\r\n",
        "\r\n",
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
        "                optimizer=tf.keras.optimizers.Adam(),\r\n",
        "                metrics=['accuracy'])\r\n",
        "\r\n",
        "model.fit(train_dataset, epochs=5)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset mnist/3.0.1 (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to data/mnist/3.0.1...\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead pass\n",
            "`try_gcs=True` to `tfds.load` or set `data_dir=gs://tfds-data/datasets`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c9f386f810e4a80954246e91facd716",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Dl Completed...', max=4.0, style=ProgressStyle(descriptio…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1mDataset mnist downloaded and prepared to data/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n",
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of devices: 1\n",
            "Epoch 1/5\n",
            "938/938 [==============================] - 30s 29ms/step - loss: 0.4012 - accuracy: 0.8814\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.0736 - accuracy: 0.9788\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.0480 - accuracy: 0.9855\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.0332 - accuracy: 0.9900\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.0262 - accuracy: 0.9919\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f780d4b5a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qppto4V5Uqc5"
      },
      "source": [
        "# Multi GPU Mirrored Strategy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3D_B_XFwPqgn",
        "outputId": "7ec379e9-2523-43d6-bf8e-1a51aef2f7fb"
      },
      "source": [
        "%reset -f\r\n",
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "\r\n",
        "# Note that it generally has a minimum of 8 cores, but if your GPU has\r\n",
        "# less, you need to set this. In this case one of my GPUs has 4 cores\r\n",
        "os.environ[\"TF_MIN_GPU_MULTIPROCESSOR_COUNT\"] = \"4\"\r\n",
        "\r\n",
        "# If the list of devices is not specified in the\r\n",
        "# `tf.distribute.MirroredStrategy` constructor, it will be auto-detected.\r\n",
        "# If you have *different* GPUs in your system, you probably have to set up cross_device_ops like this\r\n",
        "strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\r\n",
        "print ('Number of devices: {}'.format(strategy.num_replicas_in_sync))\r\n",
        "\r\n",
        "# Get the data\r\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\r\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\r\n",
        "\r\n",
        "# Adding a dimension to the array -> new shape == (28, 28, 1)\r\n",
        "# We are doing this because the first layer in our model is a convolutional\r\n",
        "# layer and it requires a 4D input (batch_size, height, width, channels).\r\n",
        "# batch_size dimension will be added later on.\r\n",
        "train_images = train_images[..., None]\r\n",
        "test_images = test_images[..., None]\r\n",
        "\r\n",
        "# Normalize the images to [0, 1] range.\r\n",
        "train_images = train_images / np.float32(255)\r\n",
        "test_images = test_images / np.float32(255)\r\n",
        "\r\n",
        "# Batch the input data\r\n",
        "BUFFER_SIZE = len(train_images)\r\n",
        "BATCH_SIZE_PER_REPLICA = 64\r\n",
        "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\r\n",
        "\r\n",
        "# Create Datasets from the batches\r\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(BUFFER_SIZE).batch(GLOBAL_BATCH_SIZE)\r\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE)\r\n",
        "\r\n",
        "# Create Distributed Datasets from the datasets\r\n",
        "train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\r\n",
        "test_dist_dataset = strategy.experimental_distribute_dataset(test_dataset)\r\n",
        "\r\n",
        "# Create the model architecture\r\n",
        "def create_model():\r\n",
        "  model = tf.keras.Sequential([\r\n",
        "      tf.keras.layers.Conv2D(32, 3, activation='relu'),\r\n",
        "      tf.keras.layers.MaxPooling2D(),\r\n",
        "      tf.keras.layers.Conv2D(64, 3, activation='relu'),\r\n",
        "      tf.keras.layers.MaxPooling2D(),\r\n",
        "      tf.keras.layers.Flatten(),\r\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\r\n",
        "      tf.keras.layers.Dense(10)\r\n",
        "    ])\r\n",
        "  return model\r\n",
        "\r\n",
        "with strategy.scope():\r\n",
        "    # We will use sparse categorical crossentropy as always. But, instead of having the loss function\r\n",
        "    # manage the map reduce across GPUs for us, we'll do it ourselves with a simple algorithm.\r\n",
        "    # Remember -- the map reduce is how the losses get aggregated\r\n",
        "    # Set reduction to `none` so we can do the reduction afterwards and divide byglobal batch size.\r\n",
        "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\r\n",
        "\r\n",
        "    def compute_loss(labels, predictions):\r\n",
        "        # Compute Loss uses the loss object to compute the loss\r\n",
        "        # Notice that per_example_loss will have an entry per GPU\r\n",
        "        # so in this case there'll be 2 -- i.e. the loss for each replica\r\n",
        "        per_example_loss = loss_object(labels, predictions)\r\n",
        "        # You can print it to see it -- you'll get output like this:\r\n",
        "        # Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(48,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\r\n",
        "        # Tensor(\"replica_1/sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(48,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\r\n",
        "        # Note in particular that replica_0 isn't named in the weighted_loss -- the first is unnamed, the second is replica_1 etc\r\n",
        "        print(per_example_loss)\r\n",
        "        return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\r\n",
        "\r\n",
        "    # We'll just reduce by getting the average of the losses\r\n",
        "    test_loss = tf.keras.metrics.Mean(name='test_loss')\r\n",
        "\r\n",
        "    # Accuracy on train and test will be SparseCategoricalAccuracy\r\n",
        "    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\r\n",
        "    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\r\n",
        "\r\n",
        "    # Optimizer will be Adam\r\n",
        "    optimizer = tf.keras.optimizers.Adam()\r\n",
        "\r\n",
        "    # Create the model within the scope\r\n",
        "    model = create_model()\r\n",
        "    \r\n",
        "# `run` replicates the provided computation and runs it\r\n",
        "# with the distributed input.\r\n",
        "@tf.function\r\n",
        "def distributed_train_step(dataset_inputs):\r\n",
        "    per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))\r\n",
        "    #tf.print(per_replica_losses.values)\r\n",
        "    return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\r\n",
        "    \r\n",
        "def train_step(inputs):\r\n",
        "    images, labels = inputs\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "        predictions = model(images, training=True)\r\n",
        "        loss = compute_loss(labels, predictions)\r\n",
        "\r\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\r\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n",
        "\r\n",
        "    train_accuracy.update_state(labels, predictions)\r\n",
        "    return loss\r\n",
        "\r\n",
        "#######################\r\n",
        "# Test Steps Functions\r\n",
        "#######################\r\n",
        "@tf.function\r\n",
        "def distributed_test_step(dataset_inputs):\r\n",
        "    return strategy.run(test_step, args=(dataset_inputs,))\r\n",
        "\r\n",
        "def test_step(inputs):\r\n",
        "    images, labels = inputs\r\n",
        "    \r\n",
        "    predictions = model(images, training=False)\r\n",
        "    t_loss = loss_object(labels, predictions)\r\n",
        "    \r\n",
        "    test_loss.update_state(t_loss)\r\n",
        "    test_accuracy.update_state(labels, predictions)\r\n",
        "\r\n",
        "\r\n",
        "EPOCHS = 5\r\n",
        "for epoch in range(EPOCHS):\r\n",
        "    # Do Training\r\n",
        "    total_loss = 0.0\r\n",
        "    num_batches = 0\r\n",
        "    for batch in train_dist_dataset:\r\n",
        "        total_loss += distributed_train_step(batch)\r\n",
        "        num_batches += 1\r\n",
        "    train_loss = total_loss / num_batches\r\n",
        "\r\n",
        "    # Do Testing\r\n",
        "    for batch in test_dist_dataset:\r\n",
        "        distributed_test_step(batch)\r\n",
        "\r\n",
        "    template = (\"Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, \" \"Test Accuracy: {}\")\r\n",
        "\r\n",
        "    print (template.format(epoch+1, train_loss, train_accuracy.result()*100, test_loss.result(), test_accuracy.result()*100))\r\n",
        "\r\n",
        "    test_loss.reset_states()\r\n",
        "    train_accuracy.reset_states()\r\n",
        "    test_accuracy.reset_states()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "Number of devices: 1\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(64,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
            "Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(64,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
            "Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(32,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
            "Epoch 1, Loss: 0.5248026251792908, Accuracy: 80.91166687011719, Test Loss: 0.41276490688323975, Test Accuracy: 84.77999877929688\n",
            "Epoch 2, Loss: 0.3458365201950073, Accuracy: 87.5233383178711, Test Loss: 0.334444135427475, Test Accuracy: 87.7300033569336\n",
            "Epoch 3, Loss: 0.2993846833705902, Accuracy: 89.14666748046875, Test Loss: 0.3124011158943176, Test Accuracy: 88.81999969482422\n",
            "Epoch 4, Loss: 0.26946088671684265, Accuracy: 90.125, Test Loss: 0.2859351634979248, Test Accuracy: 89.6500015258789\n",
            "Epoch 5, Loss: 0.2429579347372055, Accuracy: 91.14500427246094, Test Loss: 0.2912505865097046, Test Accuracy: 89.17000579833984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tui149ykTLhi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}