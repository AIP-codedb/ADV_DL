{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide and Deep Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_a = tf.keras.Input(shape=[1],name='wide_input')\n",
    "input_b = tf.keras.Input(shape=[1],name='dense_input')\n",
    "\n",
    "hidden_1 = tf.keras.layers.Dense(30,activation='relu')(input_b)\n",
    "hidden_2 = tf.keras.layers.Dense(30,activation='relu')(hidden_1)\n",
    "\n",
    "concat = tf.keras.layers.concatenate([hidden_2,input_a])\n",
    "output = tf.keras.layers.Dense(1,name='output')(concat)\n",
    "\n",
    "aux_output = tf.keras.layers.Dense(1,name='aux_output')(input_a)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_a,input_b],outputs=[output,aux_output])\n",
    "# tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True, to_file='base-model.png')\n",
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dense_input (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 30)           60          dense_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 30)           930         dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "wide_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 31)           0           dense_24[0][0]                   \n",
      "                                                                 wide_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            32          concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "aux_output (Dense)              (None, 1)            2           wide_input[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,024\n",
      "Trainable params: 1,024\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement as a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class WideAndDeepModel(tf.keras.Model):\n",
    "    def __init__(self,units=30,activation='relu',**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = tf.keras.layers.Dense(units,activation=activation)\n",
    "        self.hidden2 = tf.keras.layers.Dense(units,activation=activation)\n",
    "        self.main_output=tf.keras.layers.Dense(1)\n",
    "        self.aux_output = tf.keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        input_a,input_b = inputs\n",
    "        hidden1 = self.hidden1(input_b)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = tf.keras.layers.concatenate([input_a,hidden2])\n",
    "        main_output=self.main_output(concat)\n",
    "        aux_output=self.aux_output(hidden2)\n",
    "        \n",
    "        return main_output,aux_output\n",
    "    \n",
    "model = WideAndDeepModel()\n",
    "# tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True, to_file='base-model.png')\n",
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_a = np.ones(shape=(1,))\n",
    "input_b = np.ones(shape=(1,))\n",
    "input=input_a,input_b\n",
    "model.compile(loss='mse', optimizer='sgd')\n",
    "# model.fit(input_a,input_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"wide_and_deep_model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             multiple                  60        \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             multiple                  930       \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             multiple                  32        \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             multiple                  31        \n",
      "=================================================================\n",
      "Total params: 1,053\n",
      "Trainable params: 1,053\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Resnet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentityBlock(tf.keras.Model):\n",
    "    def __init__(self,filters,kernel_size):\n",
    "        super(IdentityBlock,self).__init__(name='')\n",
    "        \n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters,kernel_size,padding='same')\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters,kernel_size,padding='same')\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.act = tf.keras.layers.Activation('relu')\n",
    "        self.add = tf.keras.layers.Add()\n",
    "        \n",
    "    def call(self,input_tensor):\n",
    "        x = self.conv1(input_tensor)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.act(x)\n",
    "        \n",
    "        x = self.add([x,input_tensor])\n",
    "        x = self.act(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet(tf.keras.Model):\n",
    "    def __init__(self,num_classes):\n",
    "        super(Resnet,self).__init__()\n",
    "        self.conv = tf.keras.layers.Conv2D(64,7,padding='same')\n",
    "        self.bn = tf.keras.layers.BatchNormalization()\n",
    "        self.act = tf.keras.layers.Activation('relu')\n",
    "        self.max_pool = tf.keras.layers.MaxPool2D((3,3))\n",
    "        \n",
    "        self.id1a = IdentityBlock(64,3)\n",
    "        self.id1b = IdentityBlock(64,3)\n",
    "        \n",
    "        self.global_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.classifier = tf.keras.layers.Dense(num_classes,activation='softmax')\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        x = self.conv(inputs)\n",
    "        x = self.bn(x)\n",
    "        x = self.act(x)\n",
    "        x = self.max_pool(x)\n",
    "        \n",
    "        x = self.id1a(x)\n",
    "        x = self.id1b(x)\n",
    "        \n",
    "        x = self.global_pool(x)\n",
    "        return self.classifier(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(features):\n",
    "    return tf.cast(features['image'], tf.float32) / 255., features['label']\n",
    "\n",
    "resnet = Resnet(10)\n",
    "resnet.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset mnist/3.0.1 (download: Unknown size, generated: Unknown size, total: Unknown size) to data\\mnist\\3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "436daa812c164fbbb762d59ef74bb47b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Dl Completed...'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07fd65b444b2432fbac62e4638e0173c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Dl Size...'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4b9f7c645aa46689d9869a1931ebebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Extraction completed...'), FloatProgress(value=1.0, bar_style='info', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to data\\mnist\\3.0.1.incompleteVZM6IK\\mnist-train.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7de3f36c24c45f8b19f9ad7af59afff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=60000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to data\\mnist\\3.0.1.incompleteVZM6IK\\mnist-test.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6497ffc39f4efc99d189567389ea52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to data\\mnist\\3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "dataset = tfds.load('mnist', split=tfds.Split.TRAIN, data_dir='data')\n",
    "dataset = dataset.map(preprocess).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 477s 254ms/step - loss: 0.1410 - accuracy: 0.9642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2af29da3eb8>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.fit(dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom VGG Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please uncomment all lines in this cell and replace those marked with `# YOUR CODE HERE`.\n",
    "# You can select all lines in this code cell with Ctrl+A (Windows/Linux) or Cmd+A (Mac), then press Ctrl+/ (Windows/Linux) or Cmd+/ (Mac) to uncomment.\n",
    "\n",
    "\n",
    "\n",
    "class Block(tf.keras.Model):\n",
    "    def __init__(self, filters, kernel_size, repetitions, pool_size=2, strides=2):\n",
    "        super(Block, self).__init__()\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.repetitions = repetitions\n",
    "        \n",
    "        # Define a conv2D_0, conv2D_1, etc based on the number of repetitions\n",
    "        for i in range(repetitions):\n",
    "            \n",
    "            # Define a Conv2D layer, specifying filters, kernel_size, activation and padding.\n",
    "            vars(self)[f'conv2D_{i}'] = tf.keras.layers.Conv2D(filters,kernel_size,\n",
    "                                                               activation='relu',\n",
    "                                                               padding='same')\n",
    "        \n",
    "        # Define the max pool layer that will be added after the Conv2D blocks\n",
    "#         self.max_pool = tf.keras.layers.MaxPool2D(pool_size=(pool_size, pool_size),strides=(strides,strides))    \n",
    "        self.max_pool = tf.keras.layers.MaxPool2D(pool_size=pool_size,strides=strides) \n",
    "  \n",
    "    def call(self, inputs):\n",
    "        # access the class's conv2D_0 layer\n",
    "        conv2D_0 = self.conv2D_0\n",
    "        \n",
    "        # Connect the conv2D_0 layer to inputs\n",
    "        x = conv2D_0(inputs)\n",
    "\n",
    "        # for the remaining conv2D_i layers from 1 to `repetitions` they will be connected to the previous layer\n",
    "        for i in range(1,self.repetitions):\n",
    "            # access conv2D_i by formatting the integer `i`. (hint: check how these were saved using `vars()` earlier)\n",
    "            conv2D_i = vars(self)[f'conv2D_{i}']\n",
    "            \n",
    "            # Use the conv2D_i and connect it to the previous layer\n",
    "            x = conv2D_i(x)\n",
    "\n",
    "        # Finally, add the max_pool layer\n",
    "        max_pool = self.max_pool\n",
    "        \n",
    "        return max_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please uncomment all lines in this cell and replace those marked with `# YOUR CODE HERE`.\n",
    "# You can select all lines in this code cell with Ctrl+A (Windows/Linux) or Cmd+A (Mac), then press Ctrl+/ (Windows/Linux) or Cmd+/ (Mac) to uncomment.\n",
    "\n",
    "\n",
    "\n",
    "class MyVGG(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(MyVGG, self).__init__()\n",
    "\n",
    "        # Creating blocks of VGG with the following \n",
    "        # (filters, kernel_size, repetitions) configurations\n",
    "        self.block_a = Block(64,3,2)\n",
    "        self.block_b = Block(128,3,2)\n",
    "        self.block_c = Block(256,3,3)\n",
    "        self.block_d = Block(512,3,3)\n",
    "        self.block_e = Block(512,3,3)\n",
    "\n",
    "        # Classification head\n",
    "        # Define a Flatten layer\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        # Create a Dense layer with 256 units and ReLU as the activation function\n",
    "        self.fc = tf.keras.layers.Dense(256,activation='relu')\n",
    "        # Finally add the softmax classifier using a Dense layer\n",
    "        self.classifier = tf.keras.layers.Dense(num_classes,activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Chain all the layers one after the other\n",
    "        x = self.block_a(inputs)\n",
    "        x = self.block_b(x)\n",
    "        x = self.block_c(x)\n",
    "        x = self.block_d(x)\n",
    "        x = self.block_e(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to data\\cats_vs_dogs\\4.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e9d68d622c46ba937f486c5aeb2f20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed8629f8b09472ba6dee2d94bbc526e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0071823f80f0486fa7a9770ebf8d2028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74631500ae364208a6426d3495a9a415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:1738 images were corrupted and were skipped\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c08fece9314629a3ef97a4e6e59399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling cats_vs_dogs-train.tfrecord...:   0%|          | 0/23262 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset cats_vs_dogs downloaded and prepared to data\\cats_vs_dogs\\4.0.0. Subsequent calls will reuse this data.\u001b[0m\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    c:\\users\\eaikmmu\\miniconda3\\envs\\adv_dl\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:805 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-6-7cfba4073a72>:30 call  *\n        x = self.block_b(x)\n    <ipython-input-5-009ac1760a07>:30 call  *\n        x = conv2D_0(inputs)\n    c:\\users\\eaikmmu\\miniconda3\\envs\\adv_dl\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:998 __call__  **\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    c:\\users\\eaikmmu\\miniconda3\\envs\\adv_dl\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:201 assert_input_compatibility\n        raise TypeError('Inputs to a layer should be tensors. Got: %s' % (x,))\n\n    TypeError: Inputs to a layer should be tensors. Got: <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000001F0E542F6D8>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ac4480c8fc86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# Train the custom VGG model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mvgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\eaikmmu\\miniconda3\\envs\\adv_dl\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eaikmmu\\miniconda3\\envs\\adv_dl\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eaikmmu\\miniconda3\\envs\\adv_dl\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    869\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    872\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eaikmmu\\miniconda3\\envs\\adv_dl\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 726\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eaikmmu\\miniconda3\\envs\\adv_dl\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2968\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2969\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2970\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eaikmmu\\miniconda3\\envs\\adv_dl\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eaikmmu\\miniconda3\\envs\\adv_dl\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3206\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eaikmmu\\miniconda3\\envs\\adv_dl\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eaikmmu\\miniconda3\\envs\\adv_dl\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eaikmmu\\miniconda3\\envs\\adv_dl\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    975\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 977\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    978\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    c:\\users\\eaikmmu\\miniconda3\\envs\\adv_dl\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:805 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-6-7cfba4073a72>:30 call  *\n        x = self.block_b(x)\n    <ipython-input-5-009ac1760a07>:30 call  *\n        x = conv2D_0(inputs)\n    c:\\users\\eaikmmu\\miniconda3\\envs\\adv_dl\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:998 __call__  **\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    c:\\users\\eaikmmu\\miniconda3\\envs\\adv_dl\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:201 assert_input_compatibility\n        raise TypeError('Inputs to a layer should be tensors. Got: %s' % (x,))\n\n    TypeError: Inputs to a layer should be tensors. Got: <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000001F0E542F6D8>\n"
     ]
    }
   ],
   "source": [
    "dataset = tfds.load('cats_vs_dogs', split=tfds.Split.TRAIN, data_dir='data')\n",
    "\n",
    "# Initialize VGG with the number of classes \n",
    "vgg = MyVGG(num_classes=2)\n",
    "\n",
    "# Compile with losses and metrics\n",
    "vgg.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define preprocessing function\n",
    "def preprocess(features):\n",
    "    # Resize and normalize\n",
    "    image = tf.image.resize(features['image'], (224, 224))\n",
    "    return tf.cast(image, tf.float32) / 255., features['label']\n",
    "\n",
    "# Apply transformations to dataset\n",
    "dataset = dataset.map(preprocess).batch(32)\n",
    "\n",
    "# Train the custom VGG model\n",
    "vgg.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
